{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "X, y = cPickle.load(open('data/blackbox.pkl'))\n",
      "print X.shape, y.shape\n",
      "print X.min(), X.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 1875) (1000,)\n",
        "-1.73407859687 1.58310836224\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import feature_learning\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.externals import joblib\n",
      "from sklearn.cross_validation import KFold\n",
      "from os import path\n",
      "\n",
      "!rm -fR temp\n",
      "!mkdir temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: Quadro 4000\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_cv(data_X, data_y, kfold, prefix):\n",
      "    nsamples, nfeats = data_X.shape\n",
      "    cv = KFold(nsamples, n_folds=kfold, shuffle=True)\n",
      "    data_files = []\n",
      "    for i, (train_index, test_index) in enumerate(cv):\n",
      "        train_X = data_X[train_index]\n",
      "        train_y = data_y[train_index]\n",
      "        test_X = data_X[test_index]\n",
      "        test_y = data_y[test_index]\n",
      "        data_tuple = (train_X, train_y, test_X, test_y)\n",
      "        data_file = path.join('temp', prefix+\"%i.pkl\" % i)\n",
      "        joblib.dump(data_tuple, data_file)\n",
      "        data_files.append(data_file)\n",
      "    return data_files\n",
      "\n",
      "cv_files = create_cv(X, y, kfold = 3, prefix = 'blackbox_')\n",
      "print cv_files\n",
      "!ls temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['temp/blackbox_0.pkl', 'temp/blackbox_1.pkl', 'temp/blackbox_2.pkl']\n",
        "blackbox_0.pkl\t       blackbox_2.pkl\t\t  blackbox_sae_1.pkl\r\n",
        "blackbox_0.pkl_01.npy  blackbox_2.pkl_01.npy\t  blackbox_sae_1.pkl_01.npy\r\n",
        "blackbox_0.pkl_02.npy  blackbox_2.pkl_02.npy\t  blackbox_sae_1.pkl_02.npy\r\n",
        "blackbox_0.pkl_03.npy  blackbox_2.pkl_03.npy\t  blackbox_sae_1.pkl_03.npy\r\n",
        "blackbox_0.pkl_04.npy  blackbox_2.pkl_04.npy\t  blackbox_sae_1.pkl_04.npy\r\n",
        "blackbox_1.pkl\t       blackbox_sae_0.pkl\t  blackbox_sae_2.pkl\r\n",
        "blackbox_1.pkl_01.npy  blackbox_sae_0.pkl_01.npy  blackbox_sae_2.pkl_01.npy\r\n",
        "blackbox_1.pkl_02.npy  blackbox_sae_0.pkl_02.npy  blackbox_sae_2.pkl_02.npy\r\n",
        "blackbox_1.pkl_03.npy  blackbox_sae_0.pkl_03.npy  blackbox_sae_2.pkl_03.npy\r\n",
        "blackbox_1.pkl_04.npy  blackbox_sae_0.pkl_04.npy  blackbox_sae_2.pkl_04.npy\r\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import require\n",
      "from IPython.parallel import Client\n",
      "\n",
      "client = Client()\n",
      "print len(client)\n",
      "workers = client.load_balanced_view()\n",
      "\n",
      "@require('numpy', 'sklearn', 'feature_learning')\n",
      "def score_model(tasks):\n",
      "    from sklearn.externals import joblib\n",
      "    import numpy as np\n",
      "    from time import time\n",
      "    \n",
      "    model, data_file = tasks\n",
      "    train_X, train_y, test_X, test_y = joblib.load(data_file)\n",
      "    tic = time()\n",
      "    score = model.fit(train_X, train_y).score(test_X, test_y)\n",
      "    duration = time() - tic\n",
      "    return (score, duration)\n",
      "\n",
      "def benchmark_model(model, cv_files):\n",
      "    tasks = [(model, data_file) for data_file in cv_files]\n",
      "    results = workers.map(score_model, tasks, block=True)\n",
      "    scores, durations = zip(*results)\n",
      "    return scores, durations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "24\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from feature_learning import soft_thresholding\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.decomposition import RandomizedPCA\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "def make_sst_model(n_features, n_pca = 50, threshold = 0.0):\n",
      "    \"\"\"\n",
      "    create a pipeline model of sampling soft-threshold\n",
      "    feature learner\n",
      "    First Use PCA for to reduce the dimensionality to make \n",
      "    distance calculation/clustering converge faster\n",
      "    \"\"\"\n",
      "    return Pipeline(steps = [\n",
      "        ('dim_reduction', RandomizedPCA(n_components=n_pca, whiten = True, ))\n",
      "        , ('feature_map', soft_thresholding.SamplingSoftThreshold(n_components = n_features, threshold = threshold))\n",
      "        #, ('clf', SGDClassifier(loss = 'log', penalty='elasticnet', alpha = 1e-4, n_jobs=-1))\n",
      "        #, ('clf', LinearSVC(C = 1))\n",
      "        , ('clf', SVC(C = 500))\n",
      "    ])\n",
      "\n",
      "\n",
      "scores, durations = benchmark_model(make_sst_model(900), cv_files)\n",
      "print scores\n",
      "#print durations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.37425149700598803, 0.42642642642642642, 0.41741741741741739)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_kmst_model(n_features, n_pca = 50, threshold = 0.0):\n",
      "    \"\"\"\n",
      "    create a pipeline model of sampling soft-threshold\n",
      "    feature learner\n",
      "    First Use PCA for to reduce the dimensionality to make \n",
      "    distance calculation/clustering converge faster\n",
      "    \"\"\"\n",
      "    return Pipeline(steps = [\n",
      "        ('dim_reduction', RandomizedPCA(n_components=n_pca, whiten = True, ))\n",
      "        , ('feature_map1', soft_thresholding.SamplingSoftThreshold(n_components = 700, threshold = threshold))\n",
      "        , ('feature_map2', soft_thresholding.KMeansSoftThreshold(n_components = n_features, threshold = threshold, \n",
      "                                       batch_size = 1000, init='random'))\n",
      "        , ('clf', LinearSVC(C = 100))\n",
      "    ])\n",
      "\n",
      "\n",
      "scores, durations = benchmark_model(make_kmst_model(600), cv_files)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.38622754491017963, 0.40840840840840842, 0.39039039039039036)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from sklearn.base import BaseEstimator, TransformerMixin\n",
      "\n",
      "class IdentityMapper(BaseEstimator, TransformerMixin):\n",
      "    def __init__(self):\n",
      "        pass\n",
      "    def fit(self, X, y = None):\n",
      "        return self\n",
      "    def transform(self, X):\n",
      "        return X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import FeatureUnion\n",
      "from sklearn.decomposition import FastICA\n",
      "\n",
      "def make_kmst_model(n_features, n_pca = 50, threshold = 0.0):\n",
      "    \"\"\"\n",
      "    create a pipeline model of sampling soft-threshold\n",
      "    feature learner\n",
      "    First Use PCA for to reduce the dimensionality to make \n",
      "    distance calculation/clustering converge faster\n",
      "    \"\"\"\n",
      "    feature_map = FeatureUnion([\n",
      "        ('feature_map1', soft_thresholding.SamplingSoftThreshold(n_components = n_features, threshold = threshold))\n",
      "        , ('feature_map2', soft_thresholding.KMeansSoftThreshold(n_components = n_features, threshold = threshold, \n",
      "                                       batch_size = 1000, init='random'))\n",
      "        #, ('feature_map3', IdentityMapper()) \n",
      "        , ('feature_map3', FastICA(300))\n",
      "        ]\n",
      "                               \n",
      "    )\n",
      "    return Pipeline(steps = [\n",
      "        ('dim_reduction', RandomizedPCA(n_components=n_pca, whiten = True, ))\n",
      "        , ('feature_map', feature_map)\n",
      "        , ('clf', LinearSVC(C = 500))\n",
      "    ])\n",
      "\n",
      "\n",
      "scores, durations = benchmark_model(make_kmst_model(600), cv_files)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.43712574850299402, 0.43843843843843844, 0.45045045045045046)\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_kmst_model(n_features, n_pca = 50, threshold = 0.0):\n",
      "    \"\"\"\n",
      "    create a pipeline model of sampling soft-threshold\n",
      "    feature learner\n",
      "    First Use PCA for to reduce the dimensionality to make \n",
      "    distance calculation/clustering converge faster\n",
      "    \"\"\"\n",
      "    #return LinearSVC(C = 500)\n",
      "    return SVC(C = 100)\n",
      "\n",
      "scores, durations = benchmark_model(make_kmst_model(500), cv_files)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.27844311377245506, 0.22822822822822822, 0.21621621621621623)\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_kmst_model(n_features, n_pca = 50, threshold = 0.0):\n",
      "    \"\"\"\n",
      "    create a pipeline model of sampling soft-threshold\n",
      "    feature learner\n",
      "    First Use PCA for to reduce the dimensionality to make \n",
      "    distance calculation/clustering converge faster\n",
      "    \"\"\"\n",
      "    return Pipeline(steps = [\n",
      "        ('dim_reduction', RandomizedPCA(n_components=n_pca, whiten = True, ))\n",
      "        , ('feature_map', soft_thresholding.KMeansSoftThreshold(n_components = n_features, threshold = threshold, \n",
      "                                       batch_size = 100, init='random'))\n",
      "        , ('clf', LinearSVC(C = 10))\n",
      "    ])\n",
      "\n",
      "\n",
      "scores, durations = benchmark_model(make_kmst_model(600), cv_files)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## use svm alone\n",
      "svc = LinearSVC(C = 1)\n",
      "svc.fit(X, y)\n",
      "print svc.score(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'LinearSVC' object has no attribute 'core'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-4-8c9d3b0282b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msvc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0msvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'core'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_sst_model(n_features, n_pca = 50, threshold = 0.0):\n",
      "    \"\"\"\n",
      "    create a pipeline model of sampling soft-threshold\n",
      "    feature learner\n",
      "    First Use PCA for to reduce the dimensionality to make \n",
      "    distance calculation/clustering converge faster\n",
      "    \"\"\"\n",
      "    return Pipeline(steps = [\n",
      "        ('dim_reduction', RandomizedPCA(n_components=n_pca, whiten = True, ))\n",
      "        , ('feature_map', SamplingMapper(n_components = n_features, threshold = threshold))\n",
      "        #, ('clf', SGDClassifier(loss = 'log', penalty='elasticnet', alpha = 1e-4, n_jobs=-1))\n",
      "        , ('clf', LinearSVC(C = 1))\n",
      "    ])\n",
      "\n",
      "n_features_range = [30, 50, 150, 500, 750, 1500]\n",
      "train_scores = [None] * len(n_features_range)\n",
      "valid_scores = [None] * len(n_features_range)\n",
      "test_scores = [None] * len(n_features_range)\n",
      "\n",
      "for i, n_features in enumerate(n_features_range):\n",
      "    print 'testing', n_features\n",
      "    sst = make_sst_model(n_features)\n",
      "    sst.fit(train_X, train_y)\n",
      "    train_scores[i] = sst.score(train_X, train_y)\n",
      "    valid_scores[i] = sst.score(valid_X, valid_y)\n",
      "    test_scores[i] = sst.score(test_X, test_y)\n",
      "    print train_scores[i], valid_scores[i], test_scores[i]\n",
      "    \n",
      "print train_scores\n",
      "print valid_scores\n",
      "print test_scores\n",
      "\n",
      "%pylab inline --no-import\n",
      "pylab.plot(n_features_range, train_scores, c='r', hold = True, label = 'train')\n",
      "pylab.plot(n_features_range, valid_scores, c='g', hold = True, label = 'valid')\n",
      "pylab.plot(n_features_range, test_scores, c='b', hold = True, label = 'test')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from feature_learning import sparse_autoencoder\n",
      "sa = sparse_autoencoder.SparseAutoEncoder(1875, 1000, 0.1, 3e-3, 3)\n",
      "transfer_X = sa.fit(X, iprint=1, maxfun=200).transform(X)\n",
      "\n",
      "\n",
      "\n",
      "sae_files = create_cv(transfer_X, y, kfold = 3, prefix = 'blackbox_sae_')\n",
      "print sae_files\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['temp/blackbox_sae_0.pkl', 'temp/blackbox_sae_1.pkl', 'temp/blackbox_sae_2.pkl']\n",
        "(0.3413173652694611, 0.32432432432432434, 0.32732732732732733)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores, durations = benchmark_model(LinearSVC(C = 100), sae_files)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.29640718562874252, 0.26726726726726729, 0.33333333333333331)\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}