{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "X, y = cPickle.load(open('data/blackbox.pkl'))\n",
      "print X.shape, y.shape\n",
      "print X.min(), X.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 1875) (1000,)\n",
        "-1.73407859687 1.58310836224\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import feature_learning\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.externals import joblib\n",
      "from sklearn.cross_validation import KFold\n",
      "from os import path\n",
      "\n",
      "!rm -fR temp\n",
      "!mkdir temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: Quadro 4000\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_cv(data_X, data_y, kfold, prefix):\n",
      "    nsamples, nfeats = data_X.shape\n",
      "    cv = KFold(nsamples, n_folds=kfold, shuffle=True)\n",
      "    data_files = []\n",
      "    for i, (train_index, test_index) in enumerate(cv):\n",
      "        train_X = data_X[train_index]\n",
      "        train_y = data_y[train_index]\n",
      "        test_X = data_X[test_index]\n",
      "        test_y = data_y[test_index]\n",
      "        data_tuple = (train_X, train_y, test_X, test_y)\n",
      "        data_file = path.join('temp', prefix+\"%i.pkl\" % i)\n",
      "        joblib.dump(data_tuple, data_file)\n",
      "        data_files.append(data_file)\n",
      "    return data_files\n",
      "\n",
      "cv_files = create_cv(X, y, kfold = 3, prefix = 'blackbox_')\n",
      "print cv_files\n",
      "!ls temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['temp/blackbox_0.pkl', 'temp/blackbox_1.pkl', 'temp/blackbox_2.pkl']\n",
        "blackbox_0.pkl\t       blackbox_2.pkl\t\t  blackbox_sae_1.pkl\r\n",
        "blackbox_0.pkl_01.npy  blackbox_2.pkl_01.npy\t  blackbox_sae_1.pkl_01.npy\r\n",
        "blackbox_0.pkl_02.npy  blackbox_2.pkl_02.npy\t  blackbox_sae_1.pkl_02.npy\r\n",
        "blackbox_0.pkl_03.npy  blackbox_2.pkl_03.npy\t  blackbox_sae_1.pkl_03.npy\r\n",
        "blackbox_0.pkl_04.npy  blackbox_2.pkl_04.npy\t  blackbox_sae_1.pkl_04.npy\r\n",
        "blackbox_1.pkl\t       blackbox_sae_0.pkl\t  blackbox_sae_2.pkl\r\n",
        "blackbox_1.pkl_01.npy  blackbox_sae_0.pkl_01.npy  blackbox_sae_2.pkl_01.npy\r\n",
        "blackbox_1.pkl_02.npy  blackbox_sae_0.pkl_02.npy  blackbox_sae_2.pkl_02.npy\r\n",
        "blackbox_1.pkl_03.npy  blackbox_sae_0.pkl_03.npy  blackbox_sae_2.pkl_03.npy\r\n",
        "blackbox_1.pkl_04.npy  blackbox_sae_0.pkl_04.npy  blackbox_sae_2.pkl_04.npy\r\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import require\n",
      "from IPython.parallel import Client\n",
      "\n",
      "client = Client()\n",
      "print len(client)\n",
      "workers = client.load_balanced_view()\n",
      "\n",
      "@require('numpy', 'sklearn', 'feature_learning')\n",
      "def score_model(tasks):\n",
      "    from sklearn.externals import joblib\n",
      "    import numpy as np\n",
      "    from time import time\n",
      "    \n",
      "    model, data_file = tasks\n",
      "    train_X, train_y, test_X, test_y = joblib.load(data_file)\n",
      "    tic = time()\n",
      "    score = model.fit(train_X, train_y).score(test_X, test_y)\n",
      "    duration = time() - tic\n",
      "    return (score, duration)\n",
      "\n",
      "def benchmark_model(model, cv_files):\n",
      "    tasks = [(model, data_file) for data_file in cv_files]\n",
      "    results = workers.map(score_model, tasks, block=True)\n",
      "    scores, durations = zip(*results)\n",
      "    return scores, durations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "24\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from feature_learning import soft_thresholding\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.decomposition import RandomizedPCA\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "def make_sst_model(n_features, n_pca = 50, threshold = 0.0):\n",
      "    \"\"\"\n",
      "    create a pipeline model of sampling soft-threshold\n",
      "    feature learner\n",
      "    First Use PCA for to reduce the dimensionality to make \n",
      "    distance calculation/clustering converge faster\n",
      "    \"\"\"\n",
      "    return Pipeline(steps = [\n",
      "        ('dim_reduction', RandomizedPCA(n_components=n_pca, whiten = True, ))\n",
      "        , ('feature_map', soft_thresholding.SamplingSoftThreshold(n_components = n_features, threshold = threshold))\n",
      "        #, ('clf', SGDClassifier(loss = 'log', penalty='elasticnet', alpha = 1e-4, n_jobs=-1))\n",
      "        #, ('clf', LinearSVC(C = 1))\n",
      "        , ('clf', SVC(C = 500))\n",
      "    ])\n",
      "\n",
      "\n",
      "scores, durations = benchmark_model(make_sst_model(900), cv_files)\n",
      "print scores\n",
      "#print durations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.37425149700598803, 0.42642642642642642, 0.41741741741741739)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_kmst_model(n_features, n_pca = 50, threshold = 0.0):\n",
      "    \"\"\"\n",
      "    create a pipeline model of sampling soft-threshold\n",
      "    feature learner\n",
      "    First Use PCA for to reduce the dimensionality to make \n",
      "    distance calculation/clustering converge faster\n",
      "    \"\"\"\n",
      "    return Pipeline(steps = [\n",
      "        ('dim_reduction', RandomizedPCA(n_components=n_pca, whiten = True, ))\n",
      "        , ('feature_map1', soft_thresholding.SamplingSoftThreshold(n_components = 700, threshold = threshold))\n",
      "        , ('feature_map2', soft_thresholding.KMeansSoftThreshold(n_components = n_features, threshold = threshold, \n",
      "                                       batch_size = 1000, init='random'))\n",
      "        , ('clf', LinearSVC(C = 100))\n",
      "    ])\n",
      "\n",
      "\n",
      "scores, durations = benchmark_model(make_kmst_model(600), cv_files)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.38622754491017963, 0.40840840840840842, 0.39039039039039036)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from sklearn.base import BaseEstimator, TransformerMixin\n",
      "\n",
      "class IdentityMapper(BaseEstimator, TransformerMixin):\n",
      "    def __init__(self):\n",
      "        pass\n",
      "    def fit(self, X, y = None):\n",
      "        return self\n",
      "    def transform(self, X):\n",
      "        return X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import FeatureUnion\n",
      "from sklearn.decomposition import FastICA\n",
      "\n",
      "def make_kmst_model(n_features, n_pca = 50, threshold = 0.0):\n",
      "    \"\"\"\n",
      "    create a pipeline model of sampling soft-threshold\n",
      "    feature learner\n",
      "    First Use PCA for to reduce the dimensionality to make \n",
      "    distance calculation/clustering converge faster\n",
      "    \"\"\"\n",
      "    feature_map = FeatureUnion([\n",
      "        ('feature_map1', soft_thresholding.SamplingSoftThreshold(n_components = n_features, threshold = threshold))\n",
      "        , ('feature_map2', soft_thresholding.KMeansSoftThreshold(n_components = n_features, threshold = threshold, \n",
      "                                       batch_size = 1000, init='random'))\n",
      "        #, ('feature_map3', IdentityMapper()) \n",
      "        , ('feature_map3', FastICA(300))\n",
      "        ]\n",
      "                               \n",
      "    )\n",
      "    return Pipeline(steps = [\n",
      "        ('dim_reduction', RandomizedPCA(n_components=n_pca, whiten = True, ))\n",
      "        , ('feature_map', feature_map)\n",
      "        , ('clf', LinearSVC(C = 500))\n",
      "    ])\n",
      "\n",
      "\n",
      "scores, durations = benchmark_model(make_kmst_model(600), cv_files)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.43712574850299402, 0.43843843843843844, 0.45045045045045046)\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_kmst_model(n_features, n_pca = 50, threshold = 0.0):\n",
      "    \"\"\"\n",
      "    create a pipeline model of sampling soft-threshold\n",
      "    feature learner\n",
      "    First Use PCA for to reduce the dimensionality to make \n",
      "    distance calculation/clustering converge faster\n",
      "    \"\"\"\n",
      "    #return LinearSVC(C = 500)\n",
      "    return SVC(C = 100)\n",
      "\n",
      "scores, durations = benchmark_model(make_kmst_model(500), cv_files)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.27844311377245506, 0.22822822822822822, 0.21621621621621623)\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_kmst_model(n_features, n_pca = 50, threshold = 0.0):\n",
      "    \"\"\"\n",
      "    create a pipeline model of sampling soft-threshold\n",
      "    feature learner\n",
      "    First Use PCA for to reduce the dimensionality to make \n",
      "    distance calculation/clustering converge faster\n",
      "    \"\"\"\n",
      "    return Pipeline(steps = [\n",
      "        ('dim_reduction', RandomizedPCA(n_components=n_pca, whiten = True, ))\n",
      "        , ('feature_map', soft_thresholding.KMeansSoftThreshold(n_components = n_features, threshold = threshold, \n",
      "                                       batch_size = 100, init='random'))\n",
      "        , ('clf', LinearSVC(C = 10))\n",
      "    ])\n",
      "\n",
      "\n",
      "scores, durations = benchmark_model(make_kmst_model(600), cv_files)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## use svm alone\n",
      "svc = LinearSVC(C = 1)\n",
      "svc.fit(X, y)\n",
      "print svc.score(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'LinearSVC' object has no attribute 'core'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-4-8c9d3b0282b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msvc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0msvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'core'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_sst_model(n_features, n_pca = 50, threshold = 0.0):\n",
      "    \"\"\"\n",
      "    create a pipeline model of sampling soft-threshold\n",
      "    feature learner\n",
      "    First Use PCA for to reduce the dimensionality to make \n",
      "    distance calculation/clustering converge faster\n",
      "    \"\"\"\n",
      "    return Pipeline(steps = [\n",
      "        ('dim_reduction', RandomizedPCA(n_components=n_pca, whiten = True, ))\n",
      "        , ('feature_map', SamplingMapper(n_components = n_features, threshold = threshold))\n",
      "        #, ('clf', SGDClassifier(loss = 'log', penalty='elasticnet', alpha = 1e-4, n_jobs=-1))\n",
      "        , ('clf', LinearSVC(C = 1))\n",
      "    ])\n",
      "\n",
      "n_features_range = [30, 50, 150, 500, 750, 1500]\n",
      "train_scores = [None] * len(n_features_range)\n",
      "valid_scores = [None] * len(n_features_range)\n",
      "test_scores = [None] * len(n_features_range)\n",
      "\n",
      "for i, n_features in enumerate(n_features_range):\n",
      "    print 'testing', n_features\n",
      "    sst = make_sst_model(n_features)\n",
      "    sst.fit(train_X, train_y)\n",
      "    train_scores[i] = sst.score(train_X, train_y)\n",
      "    valid_scores[i] = sst.score(valid_X, valid_y)\n",
      "    test_scores[i] = sst.score(test_X, test_y)\n",
      "    print train_scores[i], valid_scores[i], test_scores[i]\n",
      "    \n",
      "print train_scores\n",
      "print valid_scores\n",
      "print test_scores\n",
      "\n",
      "%pylab inline --no-import\n",
      "pylab.plot(n_features_range, train_scores, c='r', hold = True, label = 'train')\n",
      "pylab.plot(n_features_range, valid_scores, c='g', hold = True, label = 'valid')\n",
      "pylab.plot(n_features_range, test_scores, c='b', hold = True, label = 'test')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from feature_learning import sparse_autoencoder\n",
      "sa = sparse_autoencoder.SparseAutoEncoder(1875, 1000, 0.1, 3e-3, 3)\n",
      "transfer_X = sa.fit(X, iprint=1, maxfun=200).transform(X)\n",
      "\n",
      "\n",
      "\n",
      "sae_files = create_cv(transfer_X, y, kfold = 3, prefix = 'blackbox_sae_')\n",
      "print sae_files\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['temp/blackbox_sae_0.pkl', 'temp/blackbox_sae_1.pkl', 'temp/blackbox_sae_2.pkl']\n",
        "(0.3413173652694611, 0.32432432432432434, 0.32732732732732733)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores, durations = benchmark_model(LinearSVC(C = 100), sae_files)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.29640718562874252, 0.26726726726726729, 0.33333333333333331)\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import RandomizedPCA\n",
      "\n",
      "pca = RandomizedPCA(n_components = 50, whiten=True)\n",
      "%time pca.fit(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 305 ms, sys: 30.8 ms, total: 336 ms\n",
        "Wall time: 199 ms\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "RandomizedPCA(copy=True, iterated_power=3, n_components=50, random_state=None,\n",
        "       whiten=True)"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "np.cumsum(pca.explained_variance_ratio_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "array([ 0.60970057,  0.68012191,  0.7340481 ,  0.77566772,  0.79952015,\n",
        "        0.81787769,  0.83477285,  0.84951529,  0.86156438,  0.87222993,\n",
        "        0.88216379,  0.89098581,  0.89874926,  0.90495814,  0.91090172,\n",
        "        0.91613544,  0.92124891,  0.92586531,  0.93012483,  0.93423908,\n",
        "        0.93830193,  0.94195997,  0.94539352,  0.94863856,  0.95169397,\n",
        "        0.95462351,  0.9574705 ,  0.96020657,  0.96291573,  0.96550876,\n",
        "        0.96801797,  0.9704561 ,  0.97266997,  0.97481407,  0.97687452,\n",
        "        0.97882037,  0.98074334,  0.98263029,  0.98441757,  0.98613858,\n",
        "        0.98781564,  0.9894587 ,  0.99097301,  0.99244852,  0.99390677,\n",
        "        0.99524141,  0.99649655,  0.9977109 ,  0.99886831,  1.        ])"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca_X = pca.transform(X)\n",
      "\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.cross_validation import StratifiedShuffleSplit\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "cv = StratifiedShuffleSplit(y, 3, test_size = 0.25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc = SVC(kernel = 'rbf', class_weight='auto')\n",
      "%time scores = cross_val_score(svc, pca_X, y, cv = cv, n_jobs = -1)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 12.9 ms, sys: 14.3 ms, total: 27.2 ms\n",
        "Wall time: 224 ms\n",
        "[ 0.24899598  0.2811245   0.30120482]\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "param_grid = {\n",
      "    'C': [1e2, 5e2, 5e3, 1e4, 5e4, 1e5, 5e5, 1e6, 5e6],\n",
      "    'gamma': [1e-2, 5e-2, 1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5, 1e-6, 5e-6]\n",
      "}\n",
      "clf = GridSearchCV(svc, param_grid, cv = cv, n_jobs=-1)\n",
      "%time clf.fit(pca_X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 888 ms, sys: 144 ms, total: 1.03 s\n",
        "Wall time: 2min 20s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "GridSearchCV(cv=StratifiedShuffleSplit(labels=[1 1 ..., 3 4], n_iter=3, test_size=0.25, indices=True, random_state=None),\n",
        "       estimator=SVC(C=1.0, cache_size=200, class_weight='auto', coef0=0.0, degree=3,\n",
        "  gamma=0.0, kernel='rbf', max_iter=-1, probability=False,\n",
        "  random_state=None, shrinking=True, tol=0.001, verbose=False),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=-1,\n",
        "       param_grid={'C': [100.0, 500.0, 5000.0, 10000.0, 50000.0, 100000.0, 500000.0, 1000000.0, 5000000.0], 'gamma': [0.01, 0.05, 0.001, 0.005, 0.0001, 0.0005, 1e-05, 5e-05, 1e-06, 5e-06]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print clf.best_params_\n",
      "print clf.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'C': 5000000.0, 'gamma': 0.01}\n",
        "0.366800535475\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "\n",
      "tree = ExtraTreesClassifier(min_samples_split=1, )\n",
      "\n",
      "param_grid = {\n",
      "    'n_estimators': [10, 50, 100, 200, 500],\n",
      "    'max_depth': [1, 2, 3, 4, 5],\n",
      "    'max_features': [None, 2, 5, 10]\n",
      "}\n",
      "clf = GridSearchCV(tree, param_grid, cv = cv, n_jobs=-1)\n",
      "%time clf.fit(pca_X, y)\n",
      "print clf.best_params_\n",
      "print clf.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 1.98 s, sys: 159 ms, total: 2.14 s\n",
        "Wall time: 18 s\n",
        "{'max_features': None, 'n_estimators': 500, 'max_depth': 5}\n",
        "0.277108433735\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}