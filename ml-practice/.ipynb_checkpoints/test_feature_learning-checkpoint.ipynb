{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## load data\n",
      "import cPickle\n",
      "import numpy as np\n",
      "from scipy import optimize\n",
      "\n",
      "train_digits, valid_digits, test_digits = cPickle.load(open('data/mnist.pkl'))\n",
      "train_X, train_y = train_digits\n",
      "valid_X, valid_y = valid_digits\n",
      "test_X, test_y = test_digits\n",
      "\n",
      "print train_X.shape, np.unique(train_y)\n",
      "print valid_X.shape\n",
      "print test_X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(50000, 784) [0 1 2 3 4 5 6 7 8 9]\n",
        "(10000, 784)\n",
        "(10000, 784)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load feature_learning/mlp.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import theano.tensor as T \n",
      "from theano import shared, function, config\n",
      "from feature_learning.util import *\n",
      "\n",
      "class LogisticRegressionLayer(object):\n",
      "\tdef __init__(self, nin, nout, l2_coeff,\n",
      "\t\tX = None, y = None, \n",
      "\t\ttheta = None):\n",
      "\t\tself.nin = nin \n",
      "\t\tself.nout = nout \n",
      "\t\tself.X = X or T.matrix('X')\n",
      "\t\tself.y = y or T.ivector('y')\n",
      "\t\tself.theta = theta or shared(value = np.zeros((nin*nout+nout), \n",
      "\t\t\t\t\t\t\t\t\t\tdtype = config.floatX),\n",
      "\t\t\t\t\t\t\t\t\tname = 'theta', borrow = True)\t\t\n",
      "\t\tself.W = self.theta[:nin*nout].reshape((nin, nout))\n",
      "\t\tself.b = self.theta[nin*nout:nin*nout+nout].reshape((nout, ))\n",
      "\n",
      "\t\tself.p_y_given_x = T.nnet.softmax(T.dot(self.X, self.W) + self.b)\n",
      "\t\tself.yhat = T.argmax(self.p_y_given_x, axis = 1)\n",
      "\t\tself.nll = -T.mean(T.log(self.p_y_given_x[T.arange(self.y.shape[0]), \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tself.y]))\n",
      "\t\tself.l2norm = T.sum(self.W ** 2)\n",
      "\t\tself.cost = self.nll + l2_coeff * self.l2norm \n",
      "\t\tself.gparams = T.grad(self.cost, wrt = self.theta)\n",
      "\n",
      "\tdef get_f_and_g(self, data_X, data_y):\n",
      "\t\tshared_X = share_gpu_data(data_X)\n",
      "\t\tshared_y = share_gpu_data(data_y, return_type = 'int32')\n",
      "\t\tself.cost_fn = function(inputs = [], \n",
      "\t\t\t\t\t\t\toutputs = self.cost, \n",
      "\t\t\t\t\t\t\tgivens = {\n",
      "\t\t\t\t\t\t\t\tself.X: shared_X,\n",
      "\t\t\t\t\t\t\t\tself.y: shared_y\n",
      "\t\t\t\t\t\t\t})\n",
      "\t\tself.gradient_fn = function(inputs = [],\n",
      "\t\t\t\t\t\t\toutputs = self.gparams,\n",
      "\t\t\t\t\t\t\tgivens = {\n",
      "\t\t\t\t\t\t\t\tself.X: shared_X,\n",
      "\t\t\t\t\t\t\t\tself.y: shared_y \n",
      "\t\t\t\t\t\t\t})\n",
      "\t\tdef _objective(theta_value):\n",
      "\t\t\ttheta_value = theta_value.astype(config.floatX)\n",
      "\t\t\tself.theta.set_value(theta_value)\n",
      "\t\t\treturn self.cost_fn().astype('float64')\n",
      "\t\tdef _gradient(theta_value):\n",
      "\t\t\ttheta_value = theta_value.astype(config.floatX)\n",
      "\t\t\tself.theta.set_value(theta_value)\n",
      "\t\t\treturn self.gradient_fn().astype('float64')\n",
      "\t\treturn _objective, _gradient"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nin, nout = 28 * 28, 10\n",
      "l2_coeff = 3e-3\n",
      "\n",
      "lr = LogisticRegressionLayer(nin, nout, l2_coeff)\n",
      "f, g = lr.get_f_and_g(train_X, train_y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "optimal_theta = optimize.fmin_l_bfgs_b(f, np.zeros(nin*nout+nout, dtype='float64'), g,\n",
      "                                        maxfun = 100, iprint = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}