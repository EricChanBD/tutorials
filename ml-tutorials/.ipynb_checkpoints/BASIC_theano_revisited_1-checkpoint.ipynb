{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "from theano import function, shared, config\n",
      "import numpy as np\n",
      "import theano.tensor as T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: Quadro 4000\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## load data\n",
      "train_set, valid_set, test_set = pickle.load(open('data/mnist.pkl'))\n",
      "train_x, train_y = train_set\n",
      "valid_x, valid_y = valid_set\n",
      "test_x, test_y = test_set\n",
      "print train_x.shape, train_y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(50000, 784) (50000,)\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Data_sharing for GPU\n",
      "- When using MSGD, it is encouraged to store the dataset into `shared variables` and access it based on the `minibatch index`, given a fixed and known batch size.\n",
      "- The reason behind shared variables is because of the large overhead when copying data into the GPU memory. \n",
      "- If shared variables are not used, the data would be copied on request (each minibatch individually when needed).\n",
      "- If the data is in theano shared variables, you give theano the possibility to copy the entire data on the GPU in a single call when the shared variables are constructed.\n",
      "- Afterwards, the GPU can access any minibatch by taking a slice from this shared variables, without needing to copy any information from the CPU memory.\n",
      "- Because the data points and their labels are usually of different nature, it is suggested to use different variables for labels and data.\n",
      "- Now the data is in one shared variable, and a minibatch is defined as a slice of that variable, it comes more natural to define a minibatch by indicating its index and its size.\n",
      "- If the memory in GPU is not large enough to fit the data, the code wont run appropriately. However, you can still store sufficiently small chunk of data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def share_data(data, return_type = None, borrow = True):\n",
      "    \"\"\"\n",
      "    Function that loads the dataset into shared variables,\n",
      "    so that theano can copy it into GPU memory.\n",
      "    Since copying data into GPU is slow, copying a minibatch\n",
      "    everytime would lead to a large decrease in performance.\n",
      "    \"\"\"\n",
      "    ## explicitly convert dtype to float32, save the data into GPU\n",
      "    shared_data = shared(np.asarray(data, \n",
      "                                           dtype=config.floatX),\n",
      "                                borrow = borrow)\n",
      "    if return_type:\n",
      "        shared_data = T.cast(shared_data, dtype = return_type)\n",
      "    ## return a reference to GPU copy, with an explicit casting if needed\n",
      "    return shared_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Mini-batch Stochastic Gradient Descent (MSGD)\n",
      "- The optimizer recommended for deep learning is so-called 'minibatches stochastic gradient descent'.\n",
      "- It is identical to SGD, except that we use more than one training example to make each estimate of the gradient.\n",
      "- This technique reduces variance in the estimate of gradient, and often makes better use of the hierarchical memory organization in modern computers\n",
      "- There is a tradeoff in the choice of the minibatch size B - the reduction of variance and use of SIMD instructionshelps most when increasing B from 1 to 2, but the marginal improvement fades rapidly to nothing. With large B, time is wasted in reducing the variance of the gradient estimator, that time would better spent on additinal gradient steps.\n",
      "- Optimal B is model-, dataset-, and hardware-dependent, can can be anywhere from 1 to maybe several hundreds\n",
      "- The learning result could be sensitive to minibatch size, specially when it is trained for a fixed number of epochs. \n",
      "- Regularization tech: $l1/l2$ regularization or `early-stopping`. In principle, adding a regularization term to the loss will encougrage smooth network mappings in a neural network, by penalizing large values of the parameters, which decreases the amount of nonlinearity that the network models.\n",
      "- Note that the fact that a solution is simple does not mean that it will generalize well. Empiricically, it was found that performing sumch regularization in the context of neural networks helps with generalization, sepcailly on small datasets.\n",
      "- Early-stopping combats overfitting by monitoring the model's performance on a validation set. During the training, if the model's performance ceases to improve sufficiently on the validation set, or even degrades with further optimization, then the heuristic implemented here gives up on much futher optimization.\n",
      "- The choice of when to stop is a judgemental call and a few heuristics exist, but the implementation here will make use of a strategy based on a geometrically increasing amount of patience."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class SGDOptimizer(object):\n",
      "    def __init__(self, \n",
      "                 n_train_batches,\n",
      "                 n_valid_batches,\n",
      "                 verbose = True, \n",
      "                 patience = 5000, \n",
      "                 patience_increase = 2, \n",
      "                 improvement_threshold = 0.995):\n",
      "        self.n_train_batches = n_train_batches\n",
      "        self.n_valid_batches = n_valid_batches\n",
      "        self.verbose = verbose\n",
      "        self.patience = patience\n",
      "        self.patience_increase = patience_increase\n",
      "        self.improvement_threshold = improvement_threshold\n",
      "    def optimize(self, n_epochs, train_fn, valid_fn, params):\n",
      "        validation_frequency = min(self.n_train_batches, self.patience / 2)\n",
      "        self.best_params = None\n",
      "        self.best_validation_error = np.inf\n",
      "        \n",
      "        epoch = 0\n",
      "        out_of_patience = False\n",
      "        patience = self.patience\n",
      "        while (epoch < n_epochs) and (not out_of_patience):\n",
      "            epoch += 1\n",
      "            for minibatch_index in xrange(n_train_batches):\n",
      "                train_cost = train_fn(minibatch_index)\n",
      "                niter = (epoch - 1) * n_train_batches + minibatch_index\n",
      "                if (niter + 1) % validation_frequency == 0:\n",
      "                    validation_error = np.mean([validate_fn(i) \n",
      "                                                for i in xrange(self.n_valid_batches)])\n",
      "                    if self.verbose:\n",
      "                        print 'epoch %i, minibatch %i/%i, validation error %f' % (\n",
      "                            epoch, minibatch_index + 1, self.n_train_batches,\n",
      "                            validation_error\n",
      "                        )\n",
      "                    if validation_error < self.best_validation_error:\n",
      "                        self.best_validation_error = validation_error\n",
      "                        self.best_params = [p.get_value(borrow = True) for p in params]\n",
      "                        if validation_error < self.best_validation_error * self.improvement_threshold:\n",
      "                            patience = max(self.patience, niter * self.patience_increase)\n",
      "                if patience <= niter:\n",
      "                    out_of_patience = True\n",
      "                    print 'running out of patience ...'\n",
      "                    break\n",
      "        if self.verbose:\n",
      "            print 'optimization done with best validation: %f' % self.best_validation_error\n",
      "        return self.best_params"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Congjugate Gradient"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Logistic Regression\n",
      "- A probabilistic, linear classifier - classification is done by projecting data points onto aset of hyperplances, the distance to which reflects a class membership probability\n",
      "- Mathematically, it is posterior probability is:\n",
      "$$\n",
      "P(Y=i|x,W,b)=softmax_i(Wx+b)=\\frac{e^{W_ix+b_i}}{\\sum_j{e^{W_jx+b_j}}}\n",
      "$$\n",
      "- A very common cost function for multi-classfication is the *negative log-likelihood*, which is the equivalence of maximizing the likelihood of data set.\n",
      "- The optimization method that is usually used is called `mini-batches stochastic gradient descent (MSGD)`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### implementation trick:\n",
      "\n",
      "1. define complete set of indepedent variables\n",
      "2. define dependent variables and their relationship with independent variables\n",
      "3. define functions that only use those variables (with any explicit logic anymore)\n",
      "4. to change the actual value of a variable during the function exeution:\n",
      "    - if the variable is an input - just pass the value as argument (most general)\n",
      "    - if the variable is a shared variable - use set_value()\n",
      "    - if the variable is a common variable (e.g., by T.matrix()) - use given for function binding (only works for functions, but not for depedentVar.eval())"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LogisticRegression(object):\n",
      "    def __init__(self, n_in, n_out, \n",
      "                 X = None, y = None, \n",
      "                 W = None, b = None):\n",
      "        \"\"\"\n",
      "        params here are everything that you need for calculations.\n",
      "        It should define the relationship graph of all the variables.\n",
      "        So that later functions can be defined by using those variables.\n",
      "        \"\"\"\n",
      "        self.n_in = n_in\n",
      "        self.n_out = n_out\n",
      "        self.W = W or shared(value = np.zeros((n_in, n_out),\n",
      "                                        dtype = config.floatX),\n",
      "                               name = 'W', borrow = True)\n",
      "        self.b = b or shared(value = np.zeros((n_out, ), \n",
      "                                        dtype = config.floatX),\n",
      "                               name = 'b', borrow = True)\n",
      "        self.X = X or T.matrix('X')\n",
      "        self.y = y or T.ivector('y')\n",
      "        self.p_y_given_x = T.nnet.softmax(T.dot(self.X, self.W) + self.b)\n",
      "        self.y_hat = T.argmax(self.p_y_given_x, axis = 1)\n",
      "        self.nll = -T.mean(T.log(self.p_y_given_x[T.arange(self.y.shape[0]), self.y]))\n",
      "        self.classification_rate = T.mean(T.eq(self.y_hat, self.y))\n",
      "    def get_cost_fn(self, data_x, data_y, batch_size, learning_rate = 0.13):\n",
      "        \"\"\"\n",
      "        bind data to the variables of the formula,\n",
      "        return a function with sig: minibatch_cost cost_f(minibatch_index),\n",
      "        where the cost is calculated \n",
      "        \"\"\"\n",
      "        shared_x = share_data(data_x)\n",
      "        shared_y = share_data(data_y, return_type = 'int32')\n",
      "        index = T.lscalar('index')\n",
      "        gw, gb = T.grad(self.nll, wrt = (self.W, self.b))\n",
      "        updates = [(self.W, self.W-gw), (self.b, self.b-gb)]\n",
      "        return function(inputs = [index], \n",
      "                        outputs = self.nll, \n",
      "                        updates = updates,\n",
      "                        givens = {self.X: shared_x[index*batch_size:(index+1)*batch_size],\n",
      "                                  self.y: shared_y[index*batch_size:(index+1)*batch_size]})\n",
      "    def get_score_fn(self, X, y):\n",
      "        shared_x = share_data(X)\n",
      "        shared_y = share_data(y, return_type = 'int32')\n",
      "        return function(inputs = [], \n",
      "                        outputs = [self.classification_rate, self.nll],\n",
      "                        givens = {self.X: shared_x, self.y: shared_y})\n",
      "    def bind_params(self, W_value, b_value):\n",
      "        self.W.set_value(W_value)\n",
      "        self.b.set_value(b_value)\n",
      "        return self"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_in, n_out = train_x.shape[1], 10\n",
      "lr = LogisticRegression(n_in, n_out)\n",
      "train_fn = lr.get_cost_fn(train_x, train_y, 20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print train_fn(0)\n",
      "print lr.b.get_value()\n",
      "print train_fn(1)\n",
      "print lr.b.get_value()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.30258536339\n",
        "[ -5.00000045e-02   1.00000001e-01   0.00000000e+00   5.00000007e-02\n",
        "  -3.72529030e-09  -3.72529030e-09   0.00000000e+00  -5.00000045e-02\n",
        "  -5.00000045e-02   0.00000000e+00]\n",
        "3.26523518562\n",
        "[ 0.09130771  0.08709212  0.05122827 -0.55327475  0.08248323  0.03242802\n",
        "  0.11993299  0.03930637 -0.01161899  0.06111502]\n"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## test sgd with logistic regression\n",
      "n_train, n_in = train_x.shape\n",
      "n_valid, n_in = valid_x.shape\n",
      "batch_size = 600\n",
      "n_train_batches = n_train / batch_size\n",
      "n_valid_batches = n_valid / batch_size\n",
      "n_out = 10\n",
      "\n",
      "lr = LogisticRegression(n_in, n_out)\n",
      "train_fn = lr.get_cost_fn(train_x, train_y, batch_size)\n",
      "validate_fn = lr.get_cost_fn(valid_x, valid_y, batch_size)\n",
      "\n",
      "sgd = SGDOptimizer(n_train_batches, n_valid_batches)\n",
      "optimal_w, optimal_b = sgd.optimize(1000, train_fn, validate_fn, params = (lr.W, lr.b))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch 1, minibatch 83/83, validation error 0.337476\n",
        "epoch 2, minibatch 83/83, validation error 0.304742"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 3, minibatch 83/83, validation error 0.289617"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 4, minibatch 83/83, validation error 0.280311"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 5, minibatch 83/83, validation error 0.273784"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 6, minibatch 83/83, validation error 0.268838"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 7, minibatch 83/83, validation error 0.264895"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 8, minibatch 83/83, validation error 0.261639"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 9, minibatch 83/83, validation error 0.258879"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 10, minibatch 83/83, validation error 0.256493"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 11, minibatch 83/83, validation error 0.254398"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 12, minibatch 83/83, validation error 0.252536"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 13, minibatch 83/83, validation error 0.250863"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 14, minibatch 83/83, validation error 0.249348"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 15, minibatch 83/83, validation error 0.247966"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 16, minibatch 83/83, validation error 0.246697"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 17, minibatch 83/83, validation error 0.245527"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 18, minibatch 83/83, validation error 0.244441"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 19, minibatch 83/83, validation error 0.243430"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 20, minibatch 83/83, validation error 0.242486"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 21, minibatch 83/83, validation error 0.241600"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 22, minibatch 83/83, validation error 0.240768"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 23, minibatch 83/83, validation error 0.239982"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 24, minibatch 83/83, validation error 0.239240"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 25, minibatch 83/83, validation error 0.238537"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 26, minibatch 83/83, validation error 0.237870"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 27, minibatch 83/83, validation error 0.237235"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 28, minibatch 83/83, validation error 0.236630"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 29, minibatch 83/83, validation error 0.236052"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 30, minibatch 83/83, validation error 0.235500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 31, minibatch 83/83, validation error 0.234972"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 32, minibatch 83/83, validation error 0.234465"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 33, minibatch 83/83, validation error 0.233979"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 34, minibatch 83/83, validation error 0.233512"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 35, minibatch 83/83, validation error 0.233062"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 36, minibatch 83/83, validation error 0.232630"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 37, minibatch 83/83, validation error 0.232212"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 38, minibatch 83/83, validation error 0.231809"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 39, minibatch 83/83, validation error 0.231420"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 40, minibatch 83/83, validation error 0.231044"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 41, minibatch 83/83, validation error 0.230680"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 42, minibatch 83/83, validation error 0.230328"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 43, minibatch 83/83, validation error 0.229986"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 44, minibatch 83/83, validation error 0.229655"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 45, minibatch 83/83, validation error 0.229334"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 46, minibatch 83/83, validation error 0.229022"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 47, minibatch 83/83, validation error 0.228719"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 48, minibatch 83/83, validation error 0.228424"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 49, minibatch 83/83, validation error 0.228137"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 50, minibatch 83/83, validation error 0.227857"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 51, minibatch 83/83, validation error 0.227585"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 52, minibatch 83/83, validation error 0.227320"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 53, minibatch 83/83, validation error 0.227062"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 54, minibatch 83/83, validation error 0.226810"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 55, minibatch 83/83, validation error 0.226564"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 56, minibatch 83/83, validation error 0.226324"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 57, minibatch 83/83, validation error 0.226089"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 58, minibatch 83/83, validation error 0.225860"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 59, minibatch 83/83, validation error 0.225635"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 60, minibatch 83/83, validation error 0.225416"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "running out of patience ...\n",
        "optimization done with best validation: 0.225416\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr.bind_params(optimal_w, optimal_b)\n",
      "score_valid = lr.get_score_fn(valid_x, valid_y)\n",
      "score_test = lr.get_score_fn(test_x, test_y)\n",
      "print score_valid()\n",
      "print score_test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[array(0.9429), array(0.21705274283885956, dtype=float32)]\n",
        "[array(0.9243), array(0.27065593004226685, dtype=float32)]\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}