{
 "metadata": {
  "name": "PRACTICE_greedy_ensemble"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Greedy Ensemble on Blackbox data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "blackbox_ensemble  blackbox.pkl\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "import numpy as np\n",
      "from sklearn import preprocessing\n",
      "import matplotlib.pylab as plt\n",
      "\n",
      "import os\n",
      "from os import path\n",
      "import shutil\n",
      "from sklearn.externals import joblib\n",
      "import json\n",
      "import copy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## load data\n",
      "blackbox = cPickle.load(open('data/blackbox.pkl', 'rb'))\n",
      "X, y = blackbox\n",
      "print X.shape\n",
      "print y.shape\n",
      "plt.plot(np.mean(X, axis = 0), label='X.mean')\n",
      "plt.plot(np.std(X, axis = 0), label='X.std')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 1875)\n",
        "(1000,)\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "<matplotlib.legend.Legend at 0x3452110>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## scaled version\n",
      "ScaledX = preprocessing.StandardScaler().fit_transform(X)\n",
      "plt.plot(np.mean(ScaledX, axis = 0), label='ScaledX.mean')\n",
      "plt.plot(np.std(ScaledX, axis = 0), label='ScaledX.std')\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "<matplotlib.legend.Legend at 0x2e8a5d0>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1. Grow Ensemble Models"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Create & Remove Ensemble Folder Structure"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## force to put a structure onto the ensemble folder\n",
      "## some house keeping work such as creating sub-folders, persisting different data, reading/writing configurations\n",
      "## start with the simple function interface, keep growing the interface when it is getting more complicated\n",
      "\n",
      "## create folder for ensemble\n",
      "def make_ensemble(name, context_folder):\n",
      "    ensemble_path = path.abspath(path.join(context_folder, name))\n",
      "    print \"DEBUG: \", ensemble_path\n",
      "    try:\n",
      "        os.mkdir(ensemble_path)\n",
      "        os.mkdir(path.join(ensemble_path, 'data'))\n",
      "        os.mkdir(path.join(ensemble_path, 'models'))\n",
      "        with open(path.join(ensemble_path, 'models.json'), 'wb') as f:\n",
      "            f.write('{}')\n",
      "        with open(path.join(ensemble_path, 'data.json'), 'wb') as f:\n",
      "            f.write('{}')\n",
      "        return (name, ensemble_path)\n",
      "    except Exception, ex:\n",
      "        print 'CREATING FOLDER ERROR: ensemble path', ensemble_path, 'could have existed'\n",
      "        raise ex\n",
      "        return None, None\n",
      "    \n",
      "## destroy the whole ensemble folder\n",
      "def remove_ensemble(folder):\n",
      "    shutil.rmtree(path.abspath(folder))\n",
      "    print 'REMOVE ENSEMBLE FOLDER:', path.abspath(folder)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## TEST creating ensemble model\n",
      "!ls\n",
      "ensemble_name, ensemble_path = make_ensemble('blackbox_ensemble', './data')\n",
      "#print make_ensemble('blackbox_ensemble', './data')\n",
      "!tree data/blackbox_ensemble\n",
      "!cat data/blackbox_ensemble/data.json\n",
      "remove_ensemble(ensemble_path)\n",
      "!tree blackbox_ensemble"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BASIC_sklearn_fact_book.ipynb  PRACTICE_feature_and_ensemble.ipynb\r\n",
        "data\t\t\t       PRACTICE_greedy_ensemble.ipynb\r\n",
        "FEATURE_by_clustering.ipynb    README.md\r\n",
        "FEATURE_images.ipynb\t       REGULARIZATION_sklearn_comparison.ipynb\r\n",
        "pca_vs_ica.png\r\n"
       ]
      },
      {
       "ename": "OSError",
       "evalue": "[Errno 17] File exists: '/home/dola/workspace/tutorials/ml-tutorials/data/blackbox_ensemble'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-6-b455a8d661fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## TEST creating ensemble model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'ls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mensemble_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'blackbox_ensemble'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#print make_ensemble('blackbox_ensemble', './data')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'tree data/blackbox_ensemble'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-5-57d4fff2e81a>\u001b[0m in \u001b[0;36mmake_ensemble\u001b[0;34m(name, context_folder)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'CREATING FOLDER ERROR: ensemble path'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'could have existed'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mOSError\u001b[0m: [Errno 17] File exists: '/home/dola/workspace/tutorials/ml-tutorials/data/blackbox_ensemble'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DEBUG:  /home/dola/workspace/tutorials/ml-tutorials/data/blackbox_ensemble\n",
        "CREATING FOLDER ERROR: ensemble path /home/dola/workspace/tutorials/ml-tutorials/data/blackbox_ensemble could have existed\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Data Persistance for Ensemble Folder"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## HELPER function add a json record to an existing json based configuration file\n",
      "## the format of existing configuration file should be a dictionary, keyed by string, valued by any structure\n",
      "def add_json_record(json_file, records, overwrite = False):\n",
      "    \"\"\"\n",
      "    PARAM json_file: the path of the configuration json file - dict\n",
      "    PARAM record: a (key_str, any_value) tuple in python, to be inserted in the json file \n",
      "    PARAM overwrite: whether overwrite an existing key or throw an exception\n",
      "    \"\"\"\n",
      "    json_path = path.abspath(json_file)\n",
      "    configure = json.load(open(json_path, 'rb'))\n",
      "    for (key, value) in records.items():\n",
      "        if not overwrite and key in configure:\n",
      "            #raise RuntimeError(' '.join(['key', key, 'already in the configuration file', json_path]))\n",
      "            print 'IGNORED:', ' '.join(['key', key, 'already in the configuration file', json_path])\n",
      "        else:\n",
      "            configure[key] = value\n",
      "    json.dump(configure, open(json_path, 'wb'))\n",
      "        \n",
      "def remove_json_record(json_file, key):\n",
      "    json_path = path.abspath(json_file)\n",
      "    configure = json.load(open(json_path, 'rb'))\n",
      "    del configure[key]\n",
      "    json.dump(configure, open(json_path, 'wb'))\n",
      "    \n",
      "def read_json_record(json_file, key):\n",
      "    json_path = path.abspath(json_file)\n",
      "    try:\n",
      "        return json.load(open(json_path, 'rb'))[key]\n",
      "    except:\n",
      "        return None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## TEST with add_json_record & remove_json_record\n",
      "#make_ensemble('blackbox_ensemble', context_folder = './data')\n",
      "add_json_record('data/blackbox_ensemble/data.json', {'dumb': {'pi': 3.14, 'hi': 'je;'}})\n",
      "#!cat data/blackbox_ensemble/data.json\n",
      "print read_json_record('data/blackbox_ensemble/data.json', 'dumb')\n",
      "remove_json_record('data/blackbox_ensemble/data.json', 'dumb')\n",
      "print read_json_record('data/blackbox_ensemble/data.json', 'dumb')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{u'pi': 3.14, u'hi': u'je;'}\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## persist data to data folder and record it in data.json configuration\n",
      "## later different models can load the data in a shared-memory manner\n",
      "def persist_data(ensemble_folder, data_name, data, description,\n",
      "                    compress_level = 9, overwrite=False):\n",
      "    \"\"\"\n",
      "    Write data to joblib shared-memroy file\n",
      "    \"\"\"\n",
      "    ## write data to file\n",
      "    data_file = data_name + '.pkl'\n",
      "    data_path = path.abspath(path.join(ensemble_folder, 'data', data_file))\n",
      "    store_files = joblib.dump(data, data_path, compress=compress_level)\n",
      "    store_files = map(path.abspath, store_files)\n",
      "    ## write record to config\n",
      "    config_file = path.abspath(path.join(ensemble_folder, 'data.json'))\n",
      "    config_record = {\n",
      "        data_name: {  'name': data_name\n",
      "                    , 'file': data_path\n",
      "                    , 'stores': store_files\n",
      "                    , 'description': description}\n",
      "    }\n",
      "    add_json_record(config_file, config_record, overwrite=overwrite)\n",
      "    \n",
      "def remove_data(ensemble_folder, data_name):\n",
      "    config_file = path.abspath(path.join(ensemble_folder, 'data.json'))\n",
      "    config_record = read_json_record(config_file, data_name)\n",
      "    ## delete data file\n",
      "    if config_record:\n",
      "        stores = config_record['stores']\n",
      "        for f in stores:\n",
      "            os.remove(f)\n",
      "    else:\n",
      "        #raise RuntimeError('No record in config called ' + data_name)\n",
      "        print 'IGNORED: ', 'No record in config called ' + data_name\n",
      "    ## remove configuration record\n",
      "    remove_json_record(config_file, data_name)\n",
      "    \n",
      "def load_data(ensemble_folder, data_name):\n",
      "    ## load config record\n",
      "    config_file = path.abspath(path.join(ensemble_folder, 'data.json'))\n",
      "    config_record = read_json_record(config_file, data_name)\n",
      "    ## load real data\n",
      "    data = joblib.load(config_record['file'])\n",
      "    config_record['data'] = data\n",
      "    return config_record"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## TEST persist_data\n",
      "#remove_data('data/blackbox_ensemble/', 'iris')\n",
      "from sklearn.datasets import load_iris\n",
      "iris = load_iris()\n",
      "X, y = iris.data, iris.target\n",
      "#persist_data('data/blackbox_ensemble/', 'iris', ((X, y), iris), 'iris data')\n",
      "persist_data('data/blackbox_ensemble/', data_name='iris', data=np.array([1, 2, 3, None]), description='iris data')\n",
      "print load_data('data/blackbox_ensemble', 'iris')\n",
      "!ls data/blackbox_ensemble/data/\n",
      "remove_data('data/blackbox_ensemble/', 'iris')\n",
      "!ls data/blackbox_ensemble/data/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'data': array([1, 2, 3, None], dtype=object), u'stores': [u'/home/dola/workspace/tutorials/ml-tutorials/data/blackbox_ensemble/data/iris.pkl'], u'name': u'iris', u'file': u'/home/dola/workspace/tutorials/ml-tutorials/data/blackbox_ensemble/data/iris.pkl', u'description': u'iris data'}\n",
        "iris.pkl\r\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Model Persistance for Ensemble "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## persist a model \n",
      "def persist_model(ensemble_folder, model_name, model, \n",
      "                    train_data = None, validation_data = None, test_data = None, \n",
      "                    description = '', overwrite=False, **args):\n",
      "    \"\"\"\n",
      "    PARAM ensemble_folder: path to ensemble root folder\n",
      "    PARAM model_name: the key of model in models.json\n",
      "    PARAM model: the persistable model\n",
      "    PARAM train_data: name tuple (X, y) of data used for training or None\n",
      "    PARAM valid_data: name tuple (X, y) of data used for validation or None\n",
      "    PARAM test_data: name tuple (X, y) of data used for testing or None, y could be None\n",
      "    \"\"\"\n",
      "    config_file = path.abspath(path.join(ensemble_folder, 'models.json'))\n",
      "    model_path = path.abspath(path.join(ensemble_folder, 'models', model_name+'.pkl'))\n",
      "    store_files = joblib.dump(model, model_path)\n",
      "    model_record = {model_name: {\n",
      "               'name': model_name\n",
      "             , 'file': model_path\n",
      "             , 'stores': store_files\n",
      "             , 'description': description\n",
      "             , 'train_data': train_data\n",
      "             , 'validation_data': validation_data\n",
      "             , 'test_data': test_data\n",
      "        }\n",
      "    }\n",
      "    add_json_record(config_file, model_record, overwrite=overwrite)\n",
      "    \n",
      "def remove_model(ensemble_folder, model_name):\n",
      "    config_file = path.abspath(path.join(ensemble_folder, 'models.json'))\n",
      "    config_record = read_json_record(config_file, model_name)\n",
      "    if config_record:\n",
      "        ## delete all model files\n",
      "        stores = config_record['stores']\n",
      "        for f in stores:\n",
      "            os.remove(f)\n",
      "        ## remove the configuration record\n",
      "        remove_json_record(config_file, model_name)\n",
      "    else:\n",
      "        #raise RuntimeError('no record found in ', model_name)\n",
      "        print 'IGNORED: ', 'No record in config called ' + model_name\n",
      "\n",
      "def load_model(ensemble_folder, model_name):\n",
      "    ## load configuration record\n",
      "    config_file = path.abspath(path.join(ensemble_folder, 'models.json'))\n",
      "    config_record = read_json_record(config_file, model_name)\n",
      "    ## load real model file and populate to the record\n",
      "    model = joblib.load(config_record['file'])\n",
      "    config_record['model'] = model\n",
      "    return config_record\n",
      "\n",
      "def update_model(ensemble_folder, model_name, new_config):\n",
      "    model_config = load_model(ensemble_folder, model_name)\n",
      "    model_config.update(new_config)\n",
      "    remove_model(ensemble_folder, model_name)\n",
      "    persist_model(ensemble_folder, model_name, overwrite=True, **model_config)\n",
      "\n",
      "def copy_model(ensemble_folder, from_model, to_model):\n",
      "    ## load model configure\n",
      "    ## copy model pickle and \n",
      "    ## TODO: REALLY NECESSARY?\n",
      "    raise RuntimeError('NOT IMPLEMENTED')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## TEST model persistance\n",
      "from sklearn.datasets import load_digits\n",
      "from sklearn import svm\n",
      "from sklearn import cross_validation\n",
      "digits = load_digits()\n",
      "X, y = digits.data, digits.target\n",
      "train_X, valid_X, train_y, valid_y = cross_validation.train_test_split(X, y, test_size = 0.3, )\n",
      "## persist data\n",
      "persist_data('./data/blackbox_ensemble/', 'digits_train', (train_X, train_y), \"digits train set\")\n",
      "persist_data('./data/blackbox_ensemble/', 'digits_valid', (valid_X, valid_y), 'digits valid set')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## TEST train and persist model\n",
      "svc = svm.SVC()\n",
      "#svc.fit(X, y)\n",
      "persist_model('data/blackbox_ensemble/', 'digits_svc', svc, train_data = 'digits_train', )\n",
      "print load_model('data/blackbox_ensemble/', 'digits_svc')\n",
      "update_model('data/blackbox_ensemble/', 'digits_svc', {'description': 'UPATED MODEL', 'validation_data': 'digits_valid'})\n",
      "print load_model('data/blackbox_ensemble/', 'digits_svc')\n",
      "#remove_model('data/blackbox_ensemble/', 'digits_svc')\n",
      "!ls data/blackbox_ensemble/models"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{u'stores': [u'/home/dola/workspace/tutorials/ml-tutorials/data/blackbox_ensemble/models/digits_svc.pkl'], u'name': u'digits_svc', u'validation_data': None, u'test_data': None, u'file': u'/home/dola/workspace/tutorials/ml-tutorials/data/blackbox_ensemble/models/digits_svc.pkl', 'model': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, shrinking=True, tol=0.001,\n",
        "  verbose=False), u'train_data': u'digits_train', u'description': u''}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "{u'stores': [u'/home/dola/workspace/tutorials/ml-tutorials/data/blackbox_ensemble/models/digits_svc.pkl'], u'name': u'digits_svc', u'validation_data': u'digits_valid', u'test_data': None, u'file': u'/home/dola/workspace/tutorials/ml-tutorials/data/blackbox_ensemble/models/digits_svc.pkl', 'model': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, shrinking=True, tol=0.001,\n",
        "  verbose=False), u'train_data': u'digits_train', u'description': u'UPATED MODEL'}\n",
        "digits_svc.pkl\r\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Model - Data Interaction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## fit model on data\n",
      "def fit_model(ensemble_folder, model_name, data_name):\n",
      "    \"\"\"\n",
      "    PARAM ensemble_folder: the root folder of the ensemble\n",
      "    PARAM model_name: the key (string) of the model\n",
      "    PARAM dataset: type of data set on which the model is fit {'train_data', 'validation_data', 'test_data'}\n",
      "    \"\"\"\n",
      "    ## load model and data\n",
      "    model_config = load_model(ensemble_folder, model_name)\n",
      "    #if dataset in ['train_data', 'validation_data', 'test_data']:\n",
      "    #    data_name = model_config[dataset]\n",
      "    #else:\n",
      "    #    raise RuntimeError(\"NOT RECOGNIZED %s is NOT ONE OF {'train_data', 'validation_data', 'test_data'}\" % dataset )\n",
      "    model = model_config['model']\n",
      "    data_config = load_data(ensemble_folder, data_name)\n",
      "    X, y = data_config['data']\n",
      "    ## fit model to data\n",
      "    model.fit(X, y)\n",
      "    model_config['model'] = model\n",
      "    model_config['train_data'] = data_name\n",
      "    ## persistant updated model back\n",
      "    update_model(ensemble_folder, model_name, model_config)\n",
      "    return model\n",
      "    \n",
      "## predict by model\n",
      "def predict_model(ensemble_folder, model_name, data_name, probability=True):\n",
      "    \"\"\"\n",
      "    PARAM probabilit: use predict_proba or predict for prediction\n",
      "    RETURN (target, prediction) for the dataset, target could be None\n",
      "    \"\"\"\n",
      "    model_config = load_model(ensemble_folder, model_name)\n",
      "    model = model_config['model']\n",
      "    #data_name = model_config[dataset]\n",
      "    X, y = load_data(ensemble_folder, data_name)['data']\n",
      "    if probability:\n",
      "        yhat = model.predict_proba(X)\n",
      "    else:\n",
      "        yhat = model.predict(X)\n",
      "    return (y, yhat)\n",
      "## TODO - evaluate model's performance"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## TEST fit model\n",
      "## train on train data and predict on validation data\n",
      "from sklearn import metrics\n",
      "fit_model('data/blackbox_ensemble/', 'digits_svc', data_name='digits_train')\n",
      "(y, yhat) = predict_model('data/blackbox_ensemble/', 'digits_svc', data_name='digits_valid', probability=False)\n",
      "print metrics.classification_report(y, yhat)\n",
      "## train on validatoin data and update model\n",
      "## predict on validation data\n",
      "fit_model('data/blackbox_ensemble/', 'digits_svc', data_name='digits_valid')\n",
      "(y, yhat) = predict_model('data/blackbox_ensemble/', 'digits_svc', data_name='digits_valid', probability=False)\n",
      "print metrics.classification_report(y, yhat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       1.00      0.55      0.71        56\n",
        "          1       1.00      0.39      0.56        51\n",
        "          2       1.00      0.77      0.87        47\n",
        "          3       1.00      0.44      0.61        55\n",
        "          4       1.00      0.43      0.60        54\n",
        "          5       1.00      0.33      0.50        57\n",
        "          6       1.00      0.50      0.67        60\n",
        "          7       1.00      0.27      0.42        60\n",
        "          8       1.00      0.04      0.08        51\n",
        "          9       0.14      1.00      0.25        49\n",
        "\n",
        "avg / total       0.92      0.46      0.53       540\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       1.00      1.00      1.00        56\n",
        "          1       1.00      1.00      1.00        51\n",
        "          2       1.00      1.00      1.00        47\n",
        "          3       1.00      1.00      1.00        55\n",
        "          4       1.00      1.00      1.00        54\n",
        "          5       1.00      1.00      1.00        57\n",
        "          6       1.00      1.00      1.00        60\n",
        "          7       1.00      1.00      1.00        60\n",
        "          8       1.00      1.00      1.00        51\n",
        "          9       1.00      1.00      1.00        49\n",
        "\n",
        "avg / total       1.00      1.00      1.00       540\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/dist-packages/numpy/lib/utils.py:1132: DeprecationWarning: The compiler package is deprecated and removed in Python 3.x.\n",
        "  import compiler\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## massively train models on data in parallel\n",
      "## THE PROCESS OF MAKING INDIVIDUAL MODELS FOR ENSEMBLE IS AS FOLLOWS:\n",
      "## 1. BUILD DIFFERENT TYPES OF DATA SET, e.g. X, y separately, and later put them together\n",
      "## 2. PLAY WITH DIFFERENT TYPES OF MODELS ON DATASETS - FIND THE REASONAL RANGE OF PARAMETERS FOR DIFFERENT MODELS\n",
      "## 3. TRAIN DIFFERENT MODELS WITH PARAMETER CONFIGURATIONS PARALLELLY AND PERSIST THEM\n",
      "def fit_persist_model(ensemble_folder, model_config, data_config):\n",
      "    \"\"\"\n",
      "    PARAM ensemble_folder: root folder of the whole ensemble\n",
      "    PARAM model_config: dict of { 'model_name': key_in_model_config \n",
      "                                 , 'model_template': template_of_model - a class\n",
      "                                 , 'meta_params': parameter_to_model\n",
      "                                 , 'description': description_of_model}\n",
      "    PARAM data_config: dict of {   'train_data': key_of_train_data_in_data_config\n",
      "                                 [, 'validation_data': key_of_validation_data_OPTIONAL]\n",
      "                                 [, 'test_data': key_of_test_data_OPTIONAL]}\n",
      "    EFFECT: build model based on template, set meta_parameters to model, and fit it on trian_data\n",
      "    persist the model on the ensemble_folder\n",
      "    \"\"\"\n",
      "    ## build model, load train_data, and set params and fit\n",
      "    model = model_config['model_template']()\n",
      "    train_X, train_y = load_data(ensemble_folder, data_config['train_data'])['data']\n",
      "    model.set_params(**model_config['meta_params'])\n",
      "    model.fit(train_X, train_y)\n",
      "    ## persist model with configuration\n",
      "    persist_model(ensemble_folder, model_config['model_name'], \n",
      "            model, train_data=data_config['train_data'], \n",
      "            validation_data=data_config['validation_data'], \n",
      "            test_data=data_config['test_data'], description=model_config['description'])\n",
      "def parallel_fit_persist_models():\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## TEST fit and persist model\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "model_config = {  'model_name': 'digits_sgd'\n",
      "                , 'model_template': SGDClassifier\n",
      "                , 'meta_params': {'alpha': 0.1, 'l1_ratio': 0.3}\n",
      "                , 'description': 'SGDClassifier for digits'}\n",
      "data_config = {   'train_data': 'digits_train'\n",
      "                , 'validation_data': 'digits_valid'\n",
      "                , 'test_data': None}\n",
      "fit_persist_model('data/blackbox_ensemble/', model_config, data_config)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = load_model('data/blackbox_ensemble/', 'digits_sgd')['model']\n",
      "(y, yhat) = predict_model('data/blackbox_ensemble/', 'digits_sgd', data_name='digits_valid', probability=False)\n",
      "print metrics.classification_report(y, yhat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.98      0.98      0.98        56\n",
        "          1       0.94      0.92      0.93        51\n",
        "          2       1.00      1.00      1.00        47\n",
        "          3       0.87      0.96      0.91        55\n",
        "          4       0.98      0.98      0.98        54\n",
        "          5       0.95      1.00      0.97        57\n",
        "          6       1.00      0.95      0.97        60\n",
        "          7       0.97      0.98      0.98        60\n",
        "          8       0.96      0.88      0.92        51\n",
        "          9       1.00      0.96      0.98        49\n",
        "\n",
        "avg / total       0.96      0.96      0.96       540\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}