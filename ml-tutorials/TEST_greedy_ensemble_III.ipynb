{
 "metadata": {
  "name": "TEST_greedy_ensemble_III"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ensemble\n",
      "import features\n",
      "from itertools import cycle\n",
      "import numpy as np\n",
      "import random\n",
      "from IPython.parallel import Client\n",
      "client = Client()\n",
      "print len(client)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "24\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "X, y = cPickle.load(open('data/blackbox.pkl', 'rb'))\n",
      "print X.shape, y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 1875) (1000,)\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## clear and create ensemble\n",
      "!rm -fR tmp/blackbox_ensemble_iii/\n",
      "ensemble_path = ensemble.new_ensemble('blackbox_ensemble_iii', 'tmp/')\n",
      "print ensemble_path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ce/mali/tutorials/ml-tutorials/tmp/blackbox_ensemble_iii"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***FEATURE and DATA ENGINEERING***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## split data into train and validation\n",
      "from sklearn.cross_validation import train_test_split\n",
      "n_samples, n_features = X.shape\n",
      "train_index, test_index = train_test_split(range(n_samples), test_size = 0.2)\n",
      "data_records = []\n",
      "data_names = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## strided subpatches of original features\n",
      "feature_patches = features.strided_seqs(range(n_features), stride = 25, subsize = 25)\n",
      "data_name_prefix = 'stride_%d_%d'\n",
      "for feats in feature_patches:\n",
      "    train_X = features.patch(X, train_index, feats)\n",
      "    train_y = features.patch(y, train_index)\n",
      "    test_X = features.patch(X, test_index, feats)\n",
      "    test_y = features.patch(y, test_index)\n",
      "    train_name = 'train_' + data_name_prefix % (feats[0], feats[-1])\n",
      "    test_name = 'test_' + data_name_prefix % (feats[0], feats[-1])\n",
      "    data_records.append([train_name, (train_X, train_y), {}])\n",
      "    data_records.append([test_name, (test_X, test_y), {}])\n",
      "    data_names.append((train_name, test_name))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## bootstraped subpatches of original features\n",
      "feature_patches = features.bootstrap_seqs(range(n_features), n_iter = 500, subsize = 15)\n",
      "data_name_prefix = 'bs_%d_%d'\n",
      "for feats in feature_patches:\n",
      "    train_X = features.patch(X, train_index, feats)\n",
      "    train_y = features.patch(y, train_index)\n",
      "    test_X = features.patch(X, test_index, feats)\n",
      "    test_y = features.patch(y, test_index)\n",
      "    train_name = 'train_' + data_name_prefix % (feats[0], feats[-1])\n",
      "    test_name = 'test_' + data_name_prefix % (feats[0], feats[-1])\n",
      "    data_records.append([train_name, (train_X, train_y), {}])\n",
      "    data_records.append([test_name, (test_X, test_y), {}])\n",
      "    data_names.append((train_name, test_name))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## tri-kmeans features \n",
      "tri_kmeans = features.TriKmeansFeatures(n_clusters = 20, \n",
      "                        feat_patches = features.bootstrap_seqs(range(n_features), \n",
      "                                                                  n_iter = 500, subsize=20), \n",
      "                        client = client)\n",
      "tri_X = tri_kmeans.fit_transform(X)\n",
      "feature_patches = features.strided_seqs(range(tri_X.shape[1]), stride = 15, subsize=30)\n",
      "data_name_prefix = 'tri_%d_%d'\n",
      "for feats in feature_patches:\n",
      "    train_X = features.patch(tri_X, train_index, feats)\n",
      "    train_y = features.patch(y, train_index)\n",
      "    test_X = features.patch(tri_X, test_index, feats)\n",
      "    test_y = features.patch(y, test_index)\n",
      "    train_name = 'train_' + data_name_prefix % (feats[0], feats[-1])\n",
      "    test_name = 'test_' + data_name_prefix % (feats[0], feats[-1])\n",
      "    data_records.append([train_name, (train_X, train_y), {}])\n",
      "    data_records.append([test_name, (test_X, test_y), {}])\n",
      "    data_names.append((train_name, test_name))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  24/24 tasks finished after   15 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## 2nd order features\n",
      "## TODO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Write data in batch\n",
      "ensemble.batch_write_data(ensemble_path, data_records)\n",
      "print len(data_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1241\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***FARM MODELS***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## different model configurations \n",
      "from sklearn import svm\n",
      "from sklearn import linear_model\n",
      "from sklearn import tree\n",
      "from sklearn.grid_search import IterGrid\n",
      "models = []\n",
      "## tree models\n",
      "tree_params = IterGrid({'criterion': ['gini', 'entropy'], 'max_depth': range(5, 16)})\n",
      "for param in tree_params:\n",
      "    model_name = 'tree_%s_%d' % (param['criterion'], param['max_depth'])\n",
      "    models.append((model_name, tree.DecisionTreeClassifier(**param)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## link models with data\n",
      "model_names = []\n",
      "model_records = []\n",
      "for (model_name, model) in models:\n",
      "    for (train_data, validation_data) in data_names:\n",
      "        model_meta = {\n",
      "          'is_probabilistic': False\n",
      "          , 'train_data': train_data\n",
      "          , 'validation_data': validation_data\n",
      "          , 'test_data': None\n",
      "        }\n",
      "        model_data_name = '__'.join([model_name, train_data, validation_data])\n",
      "        model_names.append(model_data_name)\n",
      "        model_records.append([model_data_name, model, model_meta])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## write models into ensemble\n",
      "print len(model_names)\n",
      "selected_models = range(len(model_names))\n",
      "from random import shuffle\n",
      "shuffle(selected_models)\n",
      "selected_models = selected_models[:15000]\n",
      "model_names = np.array(model_names)[selected_models]\n",
      "model_records = np.array(model_records)[selected_models]\n",
      "print len(model_names)\n",
      "ensemble.batch_write_model(ensemble_path, model_records)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "27302\n",
        "15000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## train models in parallel\n",
      "model_data_pairs = zip(model_names, cycle(['train_data']))\n",
      "ensemble.parallel_train_models(ensemble_path, model_data_pairs, client)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  24/24 tasks finished after  574 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## construct the greedy ensemble\n",
      "from sklearn.metrics import accuracy_score\n",
      "ge = ensemble.GreedyEnsemble(ensemble_path, \n",
      "                             scorefn = accuracy_score,\n",
      "                             votefn = ensemble.GreedyEnsemble.vote_major_class,\n",
      "                             client = client)\n",
      "ge.fit(model_names, verbose = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   0/24 tasks finished after    3 s"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## performance checking on training data\n",
      "print ge.score(data_type = 'train_data')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   9/9 tasks finished after    0 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done\n",
        "0.975\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## performance checking on validation_data\n",
      "print ge.score(data_type = 'validation_data')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   9/9 tasks finished after    0 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done\n",
        "0.375\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}